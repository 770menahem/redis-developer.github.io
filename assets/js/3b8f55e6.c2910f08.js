"use strict";(self.webpackChunkredis_developer_hub=self.webpackChunkredis_developer_hub||[]).push([[749],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>m});var i=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function s(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,i,a=function(e,t){if(null==e)return{};var n,i,a={},r=Object.keys(e);for(i=0;i<r.length;i++)n=r[i],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(i=0;i<r.length;i++)n=r[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var o=i.createContext({}),d=function(e){var t=i.useContext(o),n=t;return e&&(n="function"==typeof e?e(t):s(s({},t),e)),n},p=function(e){var t=d(e.components);return i.createElement(o.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},c=i.forwardRef((function(e,t){var n=e.components,a=e.mdxType,r=e.originalType,o=e.parentName,p=l(e,["components","mdxType","originalType","parentName"]),c=d(n),m=a,h=c["".concat(o,".").concat(m)]||c[m]||u[m]||r;return n?i.createElement(h,s(s({ref:t},p),{},{components:n})):i.createElement(h,s({ref:t},p))}));function m(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=n.length,s=new Array(r);s[0]=c;var l={};for(var o in t)hasOwnProperty.call(t,o)&&(l[o]=t[o]);l.originalType=e,l.mdxType="string"==typeof e?e:a,s[1]=l;for(var d=2;d<r;d++)s[d]=n[d];return i.createElement.apply(null,s)}return i.createElement.apply(null,n)}c.displayName="MDXCreateElement"},50358:(e,t,n)=>{n.d(t,{Z:()=>o});var i=n(67294),a=n(52263);const r="authorByline_VoxI",s="authorLabel_a70t",l="authorProfileImage_URwT";const o=function(e){let{frontMatter:t}=e;const{siteConfig:n}=(0,a.Z)(),o=n.customFields.authors;return i.createElement(i.Fragment,null,t.authors&&i.createElement("div",{className:"docAuthors"},i.createElement("hr",null),t.authors.map((e=>i.createElement("div",{key:e,className:r},i.createElement("img",{className:l,src:`/img/${o[e].image?o[e].image:"default_author_profile_pic.png"}`,alt:`Profile picture for ${o[e].name}`}),i.createElement("div",null,i.createElement("div",{className:s},"Author:"),i.createElement("div",null,i.createElement("a",{href:o[e].link,target:"_blank"},o[e].name),", ",o[e].title))))),i.createElement("hr",null)))}},17837:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>d,contentTitle:()=>l,default:()=>c,frontMatter:()=>s,metadata:()=>o,toc:()=>p});var i=n(87462),a=(n(67294),n(3905)),r=n(50358);const s={id:"index-gettingstarted",title:"RedisAI Tutorial",sidebar_label:"RedisAI Tutorial",slug:"/howtos/redisai/getting-started",authors:["ajeet"]},l=void 0,o={unversionedId:"howtos/redisai/getting-started/index-gettingstarted",id:"howtos/redisai/getting-started/index-gettingstarted",title:"RedisAI Tutorial",description:"RedisAI is a Redis module for executing deep learning/machine learning models and managing their data. It provides tensors as a data type and deep learning model execution on CPUs and GPUs. RedisAI turns Redis Enterprise into a full-fledged deep learning runtime.The RedisAI module is seamlessly plugged into Redis. It is a scalable platform that addresses the unique requirements for both AI training and AI inference in one server. It provides a complete software platform that allows data scientists to easily deploy and manage AI solutions for enterprise applications.",source:"@site/docs/howtos/redisai/getting-started/index-gettingstarted.mdx",sourceDirName:"howtos/redisai/getting-started",slug:"/howtos/redisai/getting-started",permalink:"/howtos/redisai/getting-started",draft:!1,editUrl:"https://github.com/redis-developer/redis-developer/edit/master/docs/howtos/redisai/getting-started/index-gettingstarted.mdx",tags:[],version:"current",lastUpdatedAt:1667495358,formattedLastUpdatedAt:"Nov 3, 2022",frontMatter:{id:"index-gettingstarted",title:"RedisAI Tutorial",sidebar_label:"RedisAI Tutorial",slug:"/howtos/redisai/getting-started",authors:["ajeet"]},sidebar:"docs",previous:{title:"Overview",permalink:"/howtos/redisai/"},next:{title:"Market-Basket Analysis using RedisAI and RedisGears",permalink:"/howtos/redisai/market-basket-analysis"}},d={},p=[{value:"Step 1. Installing RedisAI",id:"step-1-installing-redisai",level:3},{value:"Step 2. Setup Python Environment",id:"step-2-setup-python-environment",level:3},{value:"Step 3. Install PIP",id:"step-3-install-pip",level:3},{value:"Step 4. Clone the repository",id:"step-4-clone-the-repository",level:3},{value:"Step 5. Install the dependencies",id:"step-5-install-the-dependencies",level:3},{value:"Step 6. Build the ONNX Model",id:"step-6-build-the-onnx-model",level:3},{value:"Step 7: Deploy the Model into RedisAI",id:"step-7-deploy-the-model-into-redisai",level:3},{value:"Step 8. Make Some Predictions",id:"step-8-make-some-predictions",level:3},{value:"Step 9. Set the input tensor",id:"step-9-set-the-input-tensor",level:3},{value:"Step 10. Display TENSORGET in BLOB format",id:"step-10-display-tensorget-in-blob-format",level:3},{value:"Step 11. Check the predictions",id:"step-11-check-the-predictions",level:3},{value:"Step 12. Display TENSORGET META information",id:"step-12-display-tensorget-meta-information",level:3},{value:"Step 13. Display TENSORGET META information with tensor values",id:"step-13-display-tensorget-meta-information-with-tensor-values",level:3},{value:"Step 14. Run the model",id:"step-14-run-the-model",level:3},{value:"Step 15. Make the prediction",id:"step-15-make-the-prediction",level:3},{value:"References",id:"references",level:3},{value:"Redis University",id:"redis-university",level:3},{value:"RedisAI Explained",id:"redisai-explained",level:4},{value:"RedisAI from the Command Line",id:"redisai-from-the-command-line",level:4}],u={toc:p};function c(e){let{components:t,...n}=e;return(0,a.kt)("wrapper",(0,i.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)(r.Z,{frontMatter:s,mdxType:"Authors"}),(0,a.kt)("p",null,"RedisAI is a Redis module for executing deep learning/machine learning models and managing their data. It provides tensors as a data type and deep learning model execution on CPUs and GPUs. RedisAI turns Redis Enterprise into a full-fledged deep learning runtime.The RedisAI module is seamlessly plugged into Redis. It is a scalable platform that addresses the unique requirements for both AI training and AI inference in one server. It provides a complete software platform that allows data scientists to easily deploy and manage AI solutions for enterprise applications."),(0,a.kt)("p",null,"The platform combines popular open source deep learning frameworks (PyTorch, ONNXRuntime, and TensorFlow), software libraries, and Redis modules like RedisGears, RedisTimeSeries, and more. With RedisAI, AI application developers no longer have to worry about tuning databases for performance. Requiring no added infrastructure, RedisAI lets you run your inference engine where the data lives, decreasing latency."),(0,a.kt)("p",null,"Below is an interesting example of Iris (a genus of species of flowering plants with showy flowers) classification based on measurement of width and length of sepal/petals that makes up input tensors and how to load these measurements into RedisAI:"),(0,a.kt)("h3",{id:"step-1-installing-redisai"},"Step 1. Installing RedisAI"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"}," docker run \\\n   -p 6379:6379 \\\n   redislabs/redismod \\\n   --loadmodule /usr/lib/redis/modules/redisai.so \\\n     ONNX redisai_onnxruntime/redisai_onnxruntime.so\n")),(0,a.kt)("p",null,"You will see that ONNX backend getting loaded as shown below in the results."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"}," 1:C 09 Jun 2021 12:28:47.985 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo\n 1:C 09 Jun 2021 12:28:47.985 # Redis version=6.0.1, bits=64, commit=00000000, modified=0, pid=1, just started\n 1:C 09 Jun 2021 12:28:47.985 # Configuration loaded\n 1:M 09 Jun 2021 12:28:47.987 * Running mode=standalone, port=6379.\n 1:M 09 Jun 2021 12:28:47.987 # Server initialized\n 1:M 09 Jun 2021 12:28:47.987 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never > /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.\n 1:M 09 Jun 2021 12:28:47.989 * <ai> Redis version found by RedisAI: 6.0.1 - oss\n 1:M 09 Jun 2021 12:28:47.989 * <ai> RedisAI version 10003, git_sha=7f808a934dff121e188cb76fdfcc3eb1f9ec7cbf\n 1:M 09 Jun 2021 12:28:48.011 * <ai> ONNX backend loaded from /usr/lib/redis/modules/backends/redisai_onnxruntime/redisai_onnxruntime.so\n 1:M 09 Jun 2021 12:28:48.011 * Module 'ai' loaded from /usr/lib/redis/modules/redisai.so\n 1:M 09 Jun 2021 12:28:48.011 * Ready to accept connections\n")),(0,a.kt)("p",null,"You can verify if the RedisAI module is loaded or not by running the following command:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"}," 127.0.0.1:6379> info modules\n # Modules\n module:name=ai,ver=10003,api=1,filters=0,usedby=[],using=[],options=[]\n\n # ai_git\n ai_git_sha:7f808a934dff121e188cb76fdfcc3eb1f9ec7cbf\n\n # ai_load_time_configs\n ai_threads_per_queue:1\n ai_inter_op_parallelism:0\n ai_intra_op_parallelism:0\n")),(0,a.kt)("h3",{id:"step-2-setup-python-environment"},"Step 2. Setup Python Environment"),(0,a.kt)("p",null,"Ensure that Python3.8+ is installed."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"}," brew install python\n")),(0,a.kt)("p",null,"Create a Python virtual environment and activate it:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"}," python3 -m venv venv\n . ./venv/bin/activate\n")),(0,a.kt)("h3",{id:"step-3-install-pip"},"Step 3. Install PIP"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"}," pip install --upgrade pip\n")),(0,a.kt)("h3",{id:"step-4-clone-the-repository"},"Step 4. Clone the repository"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"}," git clone https://github.com/redis-developer/redisai-iris\n")),(0,a.kt)("h3",{id:"step-5-install-the-dependencies"},"Step 5. Install the dependencies"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"}," pip install -r requirements.txt\n")),(0,a.kt)("h3",{id:"step-6-build-the-onnx-model"},"Step 6. Build the ONNX Model"),(0,a.kt)("p",null,"RedisAI supports DL/ML identifiers and their respective backend libraries, including:"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"TF: The TensorFlow backend"),(0,a.kt)("li",{parentName:"ul"},"TFLITE: The TensorFlow Lite backend"),(0,a.kt)("li",{parentName:"ul"},"TORCH: The PyTorch backend"),(0,a.kt)("li",{parentName:"ul"},"ONNX: ONNXRuntime backend")),(0,a.kt)("p",null,"A complete list of supported backends is in the ",(0,a.kt)("a",{parentName:"p",href:"https://docs.redis.com/latest/modules/redisai/release-notes/redisai-1.0-release-notes/"},"release notes for each version"),"."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"}," python build.py\n")),(0,a.kt)("h3",{id:"step-7-deploy-the-model-into-redisai"},"Step 7: Deploy the Model into RedisAI"),(0,a.kt)("p",null,"A Model is a Deep Learning or Machine Learning frozen graph that was generated by some framework. The RedisAI Model data structure represents a DL/ML model that is stored in the database and can be run. Models, like any other Redis and RedisAI data structures, are identified by keys. A Model\u2019s key is created using the ",(0,a.kt)("inlineCode",{parentName:"p"},"AI.MODELSET")," command and requires the graph payload serialized as a protobuf for input."),(0,a.kt)("p",null,"NOTE: This requires redis-cli. If you don't have redis-cli, I've found the easiest way to get it is to download, build, and install Redis itself. Details can be found at ",(0,a.kt)("a",{parentName:"p",href:"https://redis.io/topics/quickstart"},"the Redis quickstart page")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"}," redis-cli -x AI.MODELSET iris ONNX CPU BLOB < iris.onnx\n")),(0,a.kt)("h3",{id:"step-8-make-some-predictions"},"Step 8. Make Some Predictions"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://oss.redis.com/redisai/commands/#aitensorset"},"The ",(0,a.kt)("inlineCode",{parentName:"a"},"AI.TENSORSET")," command")," stores a tensor as the value of a key."),(0,a.kt)("p",null,"Launch redis-cli:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"}," redis-cli\n")),(0,a.kt)("h3",{id:"step-9-set-the-input-tensor"},"Step 9. Set the input tensor"),(0,a.kt)("p",null,"This will set the key 'iris' to the 2x4 RedisAI tensor (i.e. 2 sets of inputs of 4 values each)."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"}," AI.TENSORSET iris:in FLOAT 2 4 VALUES 5.0 3.4 1.6 0.4 6.0 2.2 5.0 1.5\n")),(0,a.kt)("p",null,"where,"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"iris:in refers to the tensor's key name,"),(0,a.kt)("li",{parentName:"ul"},"FLOAT is a tensor's data type"),(0,a.kt)("li",{parentName:"ul"},"{5.0 3.4 1.6 0.4} refers to 1st item with 4 features"),(0,a.kt)("li",{parentName:"ul"},"{6.0 2.2 5.0 1.5} refers to 2nd item with 4 features")),(0,a.kt)("h3",{id:"step-10-display-tensorget-in-blob-format"},"Step 10. Display TENSORGET in BLOB format"),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"AI.TENSORGET")," command returns a tensor stored as key's value.\nThe BLOB indicates that data is in binary format and is provided via the subsequent data argument"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},' redis-cli AI.TENSORGET iris:in BLOB\n "\\x00\\x00\\xa0@\\x9a\\x99Y@\\xcd\\xcc\\xcc?\\xcd\\xcc\\xcc>\\x00\\x00\\xc0@\\xcd\\xcc\\x0c@\\x00\\x00\\xa0@\\x00\\x00\\xc0?"\n')),(0,a.kt)("h3",{id:"step-11-check-the-predictions"},"Step 11. Check the predictions"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},' redis-cli AI.TENSORGET iris:in VALUES\n 1) "5"\n 2) "3.4000000953674316"\n 3) "1.6000000238418579"\n 4) "0.40000000596046448"\n 5) "6"\n 6) "2.2000000476837158"\n 7) "5"\n 8) "1.5"\n')),(0,a.kt)("h3",{id:"step-12-display-tensorget-meta-information"},"Step 12. Display TENSORGET META information"),(0,a.kt)("p",null,"The META used with ",(0,a.kt)("inlineCode",{parentName:"p"},"AI.TENSORGET")," returns the tensor's metadata as shown below:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},' redis-cli AI.TENSORGET iris:in META\n   1) "dtype"\n   2) "FLOAT"\n   3) "shape"\n   4) 1) (integer) 2\n      2) (integer) 4\n\n')),(0,a.kt)("h3",{id:"step-13-display-tensorget-meta-information-with-tensor-values"},"Step 13. Display TENSORGET META information with tensor values"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},'  redis-cli AI.TENSORGET iris:in META VALUES\n 1) "dtype"\n 2) "FLOAT"\n 3) "shape"\n 4) 1) (integer) 2\n    2) (integer) 4\n 5) "values"\n 6) 1) "5"\n    2) "3.4000000953674316"\n    3) "1.6000000238418579"\n    4) "0.40000000596046448"\n    5) "6"\n    6) "2.2000000476837158"\n    7) "5"\n    8) "1.5"\n')),(0,a.kt)("h3",{id:"step-14-run-the-model"},"Step 14. Run the model"),(0,a.kt)("p",null,"Define inputs for the loaded model."),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"}," redis-cli AI.MODELRUN iris INPUTS iris:in OUTPUTS iris:inferences iris:scores\n OK\n")),(0,a.kt)("h3",{id:"step-15-make-the-prediction"},"Step 15. Make the prediction"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-bash"},' redis-cli AI.TENSORGET iris:inferences VALUES META\n 1) "dtype"\n 2) "INT64"\n 3) "shape"\n 4) 1) (integer) 2\n 5) "values"\n 6) 1) (integer) 0\n 2) (integer) 2\n')),(0,a.kt)("h3",{id:"references"},"References"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://github.com/redis-developer/redisai-iris"},"Sample IRIS Classification Source Code")),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("a",{parentName:"li",href:"https://oss.redis.com/redisai/"},"RedisAI - A Server for Machine and Deep Learning Models"))),(0,a.kt)("h3",{id:"redis-university"},"Redis University"),(0,a.kt)("h4",{id:"redisai-explained"},"RedisAI Explained"),(0,a.kt)("div",{class:"text--center"},(0,a.kt)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/gbiqF-eyTW4",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:!0})),(0,a.kt)("h4",{id:"redisai-from-the-command-line"},"RedisAI from the Command Line"),(0,a.kt)("div",{class:"text--center"},(0,a.kt)("iframe",{width:"560",height:"315",src:"https://www.youtube.com/embed/-w6rxLyoJdA",frameborder:"0",allow:"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture",allowfullscreen:!0})))}c.isMDXComponent=!0}}]);
(window.webpackJsonp=window.webpackJsonp||[]).push([[74],{142:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return o})),n.d(t,"metadata",(function(){return s})),n.d(t,"toc",(function(){return c})),n.d(t,"default",(function(){return p}));var a=n(3),i=n(7),r=(n(0),n(160)),o=(n(166),n(167),n(161),n(162),{id:"index-nlp",title:"Building a Pipeline for Natural Language Processing using RedisGears",sidebar_label:"Building a Pipeline for Natural Language Processing using RedisGears",slug:"/howtos/nlp"}),s={unversionedId:"howtos/nlp/index-nlp",id:"howtos/nlp/index-nlp",isDocsHomePage:!1,title:"Building a Pipeline for Natural Language Processing using RedisGears",description:"In this tutorial, you will learn how to build a pipeline for Natural Language Processing(NLP) using RedisGears. For this demonstration, we will be leveraging the Kaggle CORD19 datasets. The implementation is designed to avoid running out of memory, leveraging Redis Cluster and Redis Gears, where the use of Redis Gears allows to process data on storage without the need to move data in and out of the Redis cluster. Redis Cluster allows horizontal scalability up to 1000 nodes and together with Redis Gears provides a distributed system where data scientist/ML engineers can focus on processing steps without worry about writing tons of scaffoldings for distributed calculations.",source:"@site/docs/howtos/nlp/index-nlp.mdx",slug:"/howtos/nlp",permalink:"/howtos/nlp",editUrl:"https://github.com/redis-developer/redis-developer/edit/master/docs/howtos/nlp/index-nlp.mdx",version:"current",sidebar_label:"Building a Pipeline for Natural Language Processing using RedisGears"},c=[{value:"Step 1. Pre-requisite",id:"step-1-pre-requisite",children:[]},{value:"Step 2. Clone the repository",id:"step-2-clone-the-repository",children:[]},{value:"Step 3. Bring up the application",id:"step-3-bring-up-the-application",children:[]},{value:"Step 4. Apply cluster configuration settings",id:"step-4-apply-cluster-configuration-settings",children:[]},{value:"Step 5. Create or activate Python virtual environment",id:"step-5-create-or-activate-python-virtual-environment",children:[]},{value:"Step 6. Create new environment",id:"step-6-create-new-environment",children:[]},{value:"Step 7. Run pipeline",id:"step-7-run-pipeline",children:[]},{value:"Step 8. Validating the functionality of the NLP pipeline",id:"step-8-validating-the-functionality-of-the-nlp-pipeline",children:[]},{value:"Verifying Redis Graph populated:",id:"verifying-redis-graph-populated",children:[]},{value:"Checking API responds:",id:"checking-api-responds",children:[]}],l={toc:c};function p(e){var t=e.components,n=Object(i.a)(e,["components"]);return Object(r.b)("wrapper",Object(a.a)({},l,n,{components:t,mdxType:"MDXLayout"}),Object(r.b)("p",null,"In this tutorial, you will learn how to build a pipeline for Natural Language Processing(NLP) using RedisGears. For this demonstration, we will be leveraging the Kaggle CORD19 datasets. The implementation is designed to avoid running out of memory, leveraging Redis Cluster and Redis Gears, where the use of Redis Gears allows to process data on storage without the need to move data in and out of the Redis cluster. Redis Cluster allows horizontal scalability up to 1000 nodes and together with Redis Gears provides a distributed system where data scientist/ML engineers can focus on processing steps without worry about writing tons of scaffoldings for distributed calculations."),Object(r.b)("h3",{id:"step-1-pre-requisite"},"Step 1. Pre-requisite"),Object(r.b)("p",null,"Ensure that you install virtualenv in your system"),Object(r.b)("h3",{id:"step-2-clone-the-repository"},"Step 2. Clone the repository"),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{}),"git clone --recurse-submodules https://github.com/applied-knowledge-systems/the-pattern.git\ncd the-pattern\n")),Object(r.b)("h3",{id:"step-3-bring-up-the-application"},"Step 3. Bring up the application"),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{}),"docker-compose -f docker-compose.dev.yml up --build -d\n")),Object(r.b)("h3",{id:"step-4-apply-cluster-configuration-settings"},"Step 4. Apply cluster configuration settings"),Object(r.b)("p",null,"You can deploy PyTorch and spacy to run on RedisGears."),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{}),"bash post_start_dev.sh\n")),Object(r.b)("div",{className:"admonition admonition-important alert alert--info"},Object(r.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-heading"}),Object(r.b)("h5",{parentName:"div"},Object(r.b)("span",Object(a.a)({parentName:"h5"},{className:"admonition-icon"}),Object(r.b)("svg",Object(a.a)({parentName:"span"},{xmlns:"http://www.w3.org/2000/svg",width:"14",height:"16",viewBox:"0 0 14 16"}),Object(r.b)("path",Object(a.a)({parentName:"svg"},{fillRule:"evenodd",d:"M7 2.3c3.14 0 5.7 2.56 5.7 5.7s-2.56 5.7-5.7 5.7A5.71 5.71 0 0 1 1.3 8c0-3.14 2.56-5.7 5.7-5.7zM7 1C3.14 1 0 4.14 0 8s3.14 7 7 7 7-3.14 7-7-3.14-7-7-7zm1 3H6v5h2V4zm0 6H6v2h2v-2z"})))),"important")),Object(r.b)("div",Object(a.a)({parentName:"div"},{className:"admonition-content"}),Object(r.b)("p",{parentName:"div"},"For Data science-focused deployment, RedisCluster should be in HA mode with at least one slave for each master.\nOne need to change a few default parameters for rgcluster to accommodate the size of PyTorch and spacy libraries (each over 1GB zipped), gist with settings."))),Object(r.b)("h3",{id:"step-5-create-or-activate-python-virtual-environment"},"Step 5. Create or activate Python virtual environment"),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{}),"cd ./the-pattern-platform/\n")),Object(r.b)("h3",{id:"step-6-create-new-environment"},"Step 6. Create new environment"),Object(r.b)("p",null,"You can create it via "),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{}),"conda create -n pattern_env python=3.8\n")),Object(r.b)("p",null," or "),Object(r.b)("p",null,"Alternatively, you can activate by using the below CLI: "),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{}),"source ~/venv_cord19/bin/activate #or create new venv\npip install -r requirements.txt\n")),Object(r.b)("h3",{id:"step-7-run-pipeline"},"Step 7. Run pipeline"),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{}),"bash cluster_pipeline.sh\n")),Object(r.b)("h3",{id:"step-8-validating-the-functionality-of-the-nlp-pipeline"},"Step 8. Validating the functionality of the NLP pipeline"),Object(r.b)("p",null,"Wait for a bit and then check:"),Object(r.b)("h3",{id:"verifying-redis-graph-populated"},"Verifying Redis Graph populated:"),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{}),'redis-cli -p 9001 -h 127.0.0.1 GRAPH.QUERY cord19medical "MATCH (n:entity) RETURN count(n) as entity_count" \nredis-cli -p 9001 -h 127.0.0.1 GRAPH.QUERY cord19medical "MATCH (e:entity)-[r]->(t:entity) RETURN count(r) as edge_count"\n')),Object(r.b)("h3",{id:"checking-api-responds"},"Checking API responds:"),Object(r.b)("pre",null,Object(r.b)("code",Object(a.a)({parentName:"pre"},{}),'curl -i -H "Content-Type: application/json" -X POST -d \'{"search":"How does temperature and humidity affect the transmission of 2019-nCoV"}\' http://localhost:8080/gsearch\n')))}p.isMDXComponent=!0},162:function(e,t,n){"use strict";var a=n(0),i=n.n(a),r=n(160),o=n(169);n(161),n(55);t.a=function(e){var t=i.a.useState(!1),n=t[0],a=t[1];return i.a.createElement("div",{className:"ri-container"},i.a.createElement("div",{className:"ri-description-short"},i.a.createElement("div",{className:"ri-icon"},i.a.createElement("span",{className:"fe fe-zap"})),i.a.createElement("div",{className:"ri-detail"},i.a.createElement("div",{className:"ri-title"},i.a.createElement("a",{href:e.page},e.title)),i.a.createElement("div",{className:"ri-description"},e.description,i.a.Children.count(e.children)>0&&i.a.createElement("span",{className:"ri-more fe fe-more-horizontal",onClick:function(){return a(!n)}})))),n&&i.a.createElement("div",{className:"ri-description-long"},i.a.createElement(r.a,{components:o.a},e.children)))}},164:function(e,t,n){"use strict";var a=n(0),i=n(165);t.a=function(){var e=Object(a.useContext)(i.a);if(null==e)throw new Error("`useUserPreferencesContext` is used outside of `Layout` Component.");return e}},165:function(e,t,n){"use strict";var a=n(0),i=Object(a.createContext)(void 0);t.a=i},166:function(e,t,n){"use strict";var a=n(0),i=n.n(a),r=n(164),o=n(163),s=n(56),c=n.n(s),l=37,p=39;t.a=function(e){var t=e.lazy,n=e.block,s=e.defaultValue,d=e.values,u=e.groupId,b=e.className,h=Object(r.a)(),m=h.tabGroupChoices,g=h.setTabGroupChoices,v=Object(a.useState)(s),f=v[0],O=v[1],j=a.Children.toArray(e.children);if(null!=u){var w=m[u];null!=w&&w!==f&&d.some((function(e){return e.value===w}))&&O(w)}var y=function(e){O(e),null!=u&&g(u,e)},N=[];return i.a.createElement("div",null,i.a.createElement("ul",{role:"tablist","aria-orientation":"horizontal",className:Object(o.a)("tabs",{"tabs--block":n},b)},d.map((function(e){var t=e.value,n=e.label;return i.a.createElement("li",{role:"tab",tabIndex:0,"aria-selected":f===t,className:Object(o.a)("tabs__item",c.a.tabItem,{"tabs__item--active":f===t}),key:t,ref:function(e){return N.push(e)},onKeyDown:function(e){!function(e,t,n){switch(n.keyCode){case p:!function(e,t){var n=e.indexOf(t)+1;e[n]?e[n].focus():e[0].focus()}(e,t);break;case l:!function(e,t){var n=e.indexOf(t)-1;e[n]?e[n].focus():e[e.length-1].focus()}(e,t)}}(N,e.target,e)},onFocus:function(){return y(t)},onClick:function(){y(t)}},n)}))),t?Object(a.cloneElement)(j.filter((function(e){return e.props.value===f}))[0],{className:"margin-vert--md"}):i.a.createElement("div",{className:"margin-vert--md"},j.map((function(e,t){return Object(a.cloneElement)(e,{key:t,hidden:e.props.value!==f})}))))}},167:function(e,t,n){"use strict";var a=n(3),i=n(0),r=n.n(i);t.a=function(e){var t=e.children,n=e.hidden,i=e.className;return r.a.createElement("div",Object(a.a)({role:"tabpanel"},{hidden:n,className:i}),t)}}}]);